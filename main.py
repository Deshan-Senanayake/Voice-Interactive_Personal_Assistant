# main.py

from whisper_module import record_audio, load_whisper_model, transcribe_audio_with_model
from llm_module import ask_ollama
from tts_module import speak_text

if __name__ == "__main__":
    model = load_whisper_model("base")   # ğŸ” Only load once
    record_audio(duration=5)             # ğŸ™ï¸ Record your voice
    query = transcribe_audio_with_model(model, "input.wav")  # ğŸ§  Transcribe
    print("ğŸ—¨ï¸ You said:", query)

    response = ask_ollama(query)         # ğŸ¤– Get answer
    print("ğŸ§  Assistant:", response)

    speak_text(response)                 # ğŸ”Š Speak response
