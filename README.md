# ğŸ™ï¸ AI Voice-Interactive Personal Assistant

A fully local, offline-capable voice assistant that lets you **speak** a question and get a **spoken response** â€” powered by **Whisper**, **LLaMA2 via Ollama**, and **pyttsx3**. Built with a modern and professional **Gradio interface**.

---

## ğŸš€ Features

- ğŸ¤ Voice Input (Record your question via mic)
- ğŸ§  Whisper (STT) + LLaMA2 (via Ollama) for question answering
- ğŸ”Š Text-to-Speech using pyttsx3
- ğŸ’¬ Beautiful chat-style UI with transcript and assistant response
- ğŸ–¥ï¸ Runs 100% locally â€“ No API keys needed

---

## ğŸ“¦ Tech Stack

| Layer              | Technology        |
|-------------------|-------------------|
| Speech-to-Text     | `faster-whisper`  |
| LLM Engine         | `llama2` via `Ollama` |
| Text-to-Speech     | `pyttsx3`         |
| GUI Frontend       | `Gradio` (Blocks) |

---

## ğŸ§‘â€ğŸ’» Requirements

- Python 3.8+
- Windows/macOS/Linux
- 8GB+ RAM (recommended)
- For GPU support (optional): NVIDIA GPU with CUDA

---

## ğŸ“‚ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/ai-voice-assistant.git
cd ai-voice-assistant
```

### 2. Set Up a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

> ğŸ’¡ If you get CUDA or cuDNN errors, change Whisperâ€™s `compute_type="int8_float32"` and `device="cpu"` in `whisper_module.py`.

---

## ğŸ¤– Setup Ollama

1. Download and install **Ollama**:
   ğŸ‘‰ https://ollama.com/download

2. Pull a local LLaMA2 model:
   ```bash
   ollama pull llama2
   ```

3. Keep Ollama running in the background:
   ```bash
   ollama run llama2
   ```

---

## ğŸ§  Run the Assistant

```bash
python app.py
```

- Click "ğŸ§ Start Talking"
- Speak your question (e.g., "What is the capital of Japan?")
- Watch the transcript + assistant response appear
- Listen to the assistant speak back

---

## ğŸ“¸ Screenshot


---

## ğŸ“ License

MIT License. Use freely for personal, academic, or demo purposes.

---

## ğŸ‘¨â€ğŸ“ Author

**Deshan Senanayake**  
